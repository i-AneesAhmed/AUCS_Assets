{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üßë‚Äçüè´ Lab Session: Text Representation in NLP (Bag of Words & TF-IDF)"
      ],
      "metadata": {
        "id": "2P_domrtoO3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Learning Objectives\n",
        "- Understand text representation in NLP.  \n",
        "- Extract unique words (vocabulary) from text.  \n",
        "- Implement **Bag of Words (BoW)** manually in Python.  \n",
        "- Implement **TF-IDF** manually in Python.  \n",
        "- Compare manual implementation with library (`sklearn`).  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DJMRQOmCoSjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Part 1: Working with Text in Python\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "YfX5SE5GoWSs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS62lR7_jdtk",
        "outputId": "611d939f-448d-49b9-d3b2-df028bd67370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'love', 'nlp']\n",
            "['i', 'love', 'machine', 'learning']\n"
          ]
        }
      ],
      "source": [
        "# Sample documents\n",
        "docs = [\n",
        "    \"I love NLP\",\n",
        "    \"I love Machine Learning\"\n",
        "]\n",
        "\n",
        "# Convert to lowercase and split\n",
        "for doc in docs:\n",
        "    words = doc.lower().split()\n",
        "    print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Part 2: Finding Unique Words (Vocabulary)"
      ],
      "metadata": {
        "id": "pvUM_wzAosUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for doc in docs:\n",
        "    words = doc.lower().split()\n",
        "    all_words.extend(words)\n",
        "\n",
        "# Unique words\n",
        "vocab = sorted(set(all_words))\n",
        "print(\"Vocabulary:\", vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtNvC3k3n72e",
        "outputId": "d6035768-65f6-44e0-c045-f9a12048db9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['i', 'learning', 'love', 'machine', 'nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîπ Part 3: Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "7OWjtIE-ozMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize BoW matrix\n",
        "bow_matrix = []\n",
        "\n",
        "for doc in docs:\n",
        "    words = doc.lower().split()\n",
        "    row = []\n",
        "    for word in vocab:\n",
        "        row.append(words.count(word))  # count frequency\n",
        "    bow_matrix.append(row)\n",
        "\n",
        "print(\"BoW Matrix:\")\n",
        "for row in bow_matrix:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39Z91RbQot89",
        "outputId": "2cdb3e25-6b5b-4d89-821f-ed420d3ac83d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Matrix:\n",
            "[1, 0, 1, 0, 1]\n",
            "[1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üîπ Part 4: TF-IDF (Manual Implementation)"
      ],
      "metadata": {
        "id": "tw9tsWnjo5pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Term Frequency (TF)"
      ],
      "metadata": {
        "id": "vV8447y-o_AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_matrix = []\n",
        "\n",
        "for doc in docs:\n",
        "    words = doc.lower().split()\n",
        "    row = []\n",
        "    for word in vocab:\n",
        "        row.append(words.count(word) / len(words))  # normalized frequency\n",
        "    tf_matrix.append(row)\n",
        "\n",
        "print(\"TF Matrix:\")\n",
        "for row in tf_matrix:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D8nDhK8o1Uq",
        "outputId": "3be00c47-990a-4cfe-9904-e4e6428ccb0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Matrix:\n",
            "[0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333]\n",
            "[0.25, 0.25, 0.25, 0.25, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Inverse Document Frequency (IDF)"
      ],
      "metadata": {
        "id": "KBsdw9KEpHDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "N = len(docs)\n",
        "idf = []\n",
        "\n",
        "for word in vocab:\n",
        "    count = sum(1 for doc in docs if word in doc.lower().split())\n",
        "    idf_value = math.log(N / (1 + count))\n",
        "    idf.append(round(idf_value, 3))\n",
        "\n",
        "print(\"IDF Values:\", dict(zip(vocab, idf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02GXAcfxpDtO",
        "outputId": "2b514189-2828-431a-cb39-c7f51c608c99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF Values: {'i': -0.405, 'learning': 0.0, 'love': -0.405, 'machine': 0.0, 'nlp': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: TF-IDF = TF √ó IDF"
      ],
      "metadata": {
        "id": "QecSnlxspP5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = []\n",
        "\n",
        "for row in tf_matrix:\n",
        "    tfidf_row = []\n",
        "    for i in range(len(vocab)):\n",
        "        tfidf_row.append(round(row[i] * idf[i], 3))\n",
        "    tfidf_matrix.append(tfidf_row)\n",
        "\n",
        "print(\"TF-IDF Matrix:\")\n",
        "for row in tfidf_matrix:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPnfaVNCpKa7",
        "outputId": "d1a16abc-4d63-4db4-b58e-4ddd65aa7237"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix:\n",
            "[-0.135, 0.0, -0.135, 0.0, 0.0]\n",
            "[-0.101, 0.0, -0.101, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üîπ Part 5: Using Libraries (Preview)"
      ],
      "metadata": {
        "id": "vB5TD823pYGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Bag of Words\n",
        "cv = CountVectorizer()\n",
        "print(\"BoW (sklearn):\")\n",
        "print(cv.fit_transform(docs).toarray())\n",
        "print(\"Vocabulary:\", cv.get_feature_names_out())\n",
        "\n",
        "# TF-IDF\n",
        "tv = TfidfVectorizer()\n",
        "print(\"\\nTF-IDF (sklearn):\")\n",
        "print(tv.fit_transform(docs).toarray())\n",
        "print(\"Vocabulary:\", tv.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBnJYRtppSrB",
        "outputId": "e608c53d-f9d2-48bf-cc28-0e3229fe90bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW (sklearn):\n",
            "[[0 1 0 1]\n",
            " [1 1 1 0]]\n",
            "Vocabulary: ['learning' 'love' 'machine' 'nlp']\n",
            "\n",
            "TF-IDF (sklearn):\n",
            "[[0.         0.57973867 0.         0.81480247]\n",
            " [0.6316672  0.44943642 0.6316672  0.        ]]\n",
            "Vocabulary: ['learning' 'love' 'machine' 'nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üìù Lab Exercise"
      ],
      "metadata": {
        "id": "XBLb2lvGpgy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Use these 3 sentences:\n",
        "\n",
        "\"Data Science is fun\"\n",
        "\n",
        "\"I love Data Science\"\n",
        "\n",
        "\"I love Python\"\n",
        "\n",
        "üëâ Do the following:\n",
        "\n",
        "Extract the vocabulary.\n",
        "\n",
        "Build BoW manually.\n",
        "\n",
        "Compute TF manually.\n",
        "\n",
        "Compute TF-IDF manually.\n",
        "\n",
        "Compare results with sklearn‚Äôs CountVectorizer and TfidfVectorizer"
      ],
      "metadata": {
        "id": "I-RBwEcGppyz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNPLwjnzpadE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}